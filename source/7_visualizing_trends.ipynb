{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='index-0'></a>\n",
    "\n",
    "<a id='visualizing-trends'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing trends\n",
    "\n",
    "Texts often have a sequence. Newspapers and periodicals have volumes.\n",
    "Novels have chapters. Personal diaries have dated entries. Visualizations of\n",
    "topic models may benefit from incorporating information about where a text falls\n",
    "in a sequence.\n",
    "\n",
    "As a motivating example, consider Victor Hugo’s *Les Misérables*. Over 500,000\n",
    "words long, the book counts as a lengthy text by any\n",
    "standard.[#fn_les_mis]_ The novel comes in five volumes (“Fantine”, “Cosette”,\n",
    "“Marius”, “The Idyll in the Rue Plumet and the Epic in the Rue St. Denis”, and\n",
    "“Jean Valjean”). And within each volume we have a sequence of chapters. (And\n",
    "within each chapter we have a sequence of paragraphs, …). In this section we\n",
    "will address how to visualize topic shares in sequence.\n",
    "\n",
    "To whet your appetite, consider the rise and fall of a topic associated with\n",
    "revolutionary activity in *Les Misérables*:\n",
    "\n",
    "![_static/plot_topics_over_time_series_les_misérables.png](static/plot_topics_over_time_series_les_misérables.png)\n",
    "\n",
    "([Enjolras](https://en.wikipedia.org/wiki/Enjolras) is the leader of the\n",
    "revolutionary *Les Amis de l’ABC*.)\n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">Probabilistic models such as topic models often benefit from\n",
    "incorporating information about where an individual text falls in a larger\n",
    "sequence of texts [[BL06]](references.ipynb#blei-dynamic-2006)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting trends\n",
    "\n",
    "As always, we first need to fit a topic model to the corpus. As MALLET has no\n",
    "built-in French stopword list we need to provide one. We will use the [French\n",
    "stopword list](http://svn.tartarus.org/snowball/trunk/website/algorithms/french/stop.txt)\n",
    "from the Snowball stemmer package. Additionally, because we are dealing with\n",
    "non-English text we need to use an alternate regular expression for\n",
    "tokenization. Token-regex '[\\p{L}\\p{M}]+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the matrix holds the topic proportions associated with\n",
    "a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import dariah\n",
    "import cophi\n",
    "\n",
    "jupyter_path = Path.cwd()\n",
    "directory= Path.joinpath(jupyter_path.resolve().parent.parent, 'data', 'hugo-les-misérables-split')\n",
    "\n",
    "corpus = cophi.corpus(directory,\n",
    "                      lowercase=True,\n",
    "                      token_pattern=r\"\\p{Letter}+\\p{Connector_Punctuation}?\\p{Letter}+\",\n",
    "                      metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfw = corpus.mfw(50)\n",
    "features = mfw + corpus.hapax\n",
    "dtm = corpus.drop(corpus.dtm, features).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mallet becomes here a global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\mallet'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "mallet_path = os.environ.get(\"MALLET_HOME\")\n",
    "mallet_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get to use DARIAH Tools again to simplify the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'C:\\mallet' is not a file. Point to the 'mallet/bin/mallet' file.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-4efdd37c3496>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m model = dariah.core.LDA(num_topics=50,\n\u001B[0m\u001B[0;32m      2\u001B[0m                         \u001B[0mnum_iterations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                         mallet=mallet_path)\n\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sib27sm\\venv\\lib\\site-packages\\dariah\\core\\modeling.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, num_topics, num_iterations, alpha, eta, random_state, mallet)\u001B[0m\n\u001B[0;32m     63\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mPath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m                 raise OSError(\n\u001B[0m\u001B[0;32m     66\u001B[0m                     \u001B[1;34m\"'{}' is not a file. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m                     \u001B[1;34m\"Point to the 'mallet/bin/mallet' file.\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: 'C:\\mallet' is not a file. Point to the 'mallet/bin/mallet' file."
     ]
    }
   ],
   "source": [
    "model = dariah.core.LDA(num_topics=50,\n",
    "                        num_iterations=1000,\n",
    "                        mallet=mallet_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.topic_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.topic_document.to_csv('doc_topics_hugo-les-misérables_50.csv', index=True)\n",
    "model.topics.to_csv('topics_hugo-les-misérables_50.csv', index=True)\n",
    "model.topic_word.to_csv('word_hugo-les-misérables_50.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the fifty topics there is one topic (#35 using 0-based indexing) that\n",
    "jumps out as characteristic of events towards the close of the novel. The words\n",
    "most strongly connected with this topic include “barricade”, “fusil”, and\n",
    "“cartouches” (“barricade”, “rifle”, and “cartridges”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "model.topics.iloc[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the documents are ordered in a sequence, we can plot the fate, so to\n",
    "speak, of this topic over time (for topic #35) with the following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "series = model.topic_document.T.iloc[:, 35].values\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.savefig('plot_topics_over_time_series_simple.png') #width=7in\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Documents over time for topic 35\")\n",
    "plt.plot(series, '.')  # '.' specifies the type of mark to use on the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this visualization communicates the essential information about the\n",
    "prevalence of a topic in the corpus, it is not perfect. We can improve it. It\n",
    "would, for instance, be useful to include an indication of where the various\n",
    "volumes start and end. Another enhancement would add some kind of “smoothing” to\n",
    "the time series in order to better communicate the underlying trend.\n",
    "\n",
    "A rolling average of the topic shares turns out be a useful form of smoothing in\n",
    "this case. We are interested in the prevalence of a topic over time and whether\n",
    "a topic disappears completely in one 500-word chunk of text (only to reappear in\n",
    "the next) does not interest us. We want to visualize the underlying trend, that\n",
    "is, we need some model or heuristic capable of capturing the idea\n",
    "that the topic (or any similar feature) has an underlying propensity to appear at\n",
    "varying points of the novel and that while this propensity may change over time it\n",
    "does not fluctuate wildly. <sup>[2](#fn-lowess)</sup>\n",
    "\n",
    "Recall that a rolling or moving average of a time series associates with each\n",
    "point in the series the average of some fixed number of previous\n",
    "observations (including the current observation). This fixed number of\n",
    "observations is often\n",
    "called a “window”. The idea of a rolling mean is effectively communicated visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "z = np.array([  3.,   2.,   3.,   6.,   2.,   3.,   1.,   3.,   8.,   3.,   5.,\n",
    "               8.,   7.,   8.,   7.,   6.,   8.,   7.,   7.,   5.,   8.,   6.,\n",
    "              11.,   6.,   7.,   8.,   8.,   6.,   9.,  15.,  13.,  10.,   9.])\n",
    "\n",
    "def rolling_mean(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "rolling_mean(z, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.plot(z, '.', alpha=0.5)\n",
    "\n",
    "plt.savefig('plot_topics_over_time_rolling_mean.png') #width=5in\n",
    "plt.plot(rolling_mean(z, 5), '-', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making these two improvements—marking the volume boundaries and adding\n",
    "a trend line based on a rolling average—the time series for our topic does\n",
    "a better job of orienting us in the novel and communicating the points in the\n",
    "novel where the topic appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docnames = list(model.topic_document.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# the values on the x-axis (xs) are simply a sequence of integers\n",
    "# corresponding to the texts (also the rows in the document topic matrix)\n",
    "xs = np.arange(len(series))\n",
    "\n",
    "series_smooth = rolling_mean(series, 15)  # 15 seems to work well here\n",
    "\n",
    "# now we need to calculate at what index each volume starts\n",
    "# there are many ways to do this, two methods are shown below\n",
    "# method #1\n",
    "volume_names = [\"tome-1-fantine\", \"tome-2-cosette\", \"tome-3-marius\", \"tome-4\", \"tome-5-jean-valjean\"]\n",
    "volume_indexes = []\n",
    "for volname in volume_names:\n",
    "    for i, docname in enumerate(docnames):\n",
    "        if volname in docname:\n",
    "            volume_indexes.append(i)\n",
    "            break\n",
    "\n",
    "try:\n",
    "    volume_indexes_prev = volume_indexes\n",
    "except:\n",
    "    print('An exception occured')\n",
    "    \n",
    "# method #2, use NumPy functions\n",
    "volume_indexes = []\n",
    "for volname in volume_names:\n",
    "    volume_indexes.append(np.min(np.nonzero([volname in docname for docname in docnames])))\n",
    "\n",
    "try:\n",
    "    volume_indexes == volume_indexes_prev\n",
    "except:\n",
    "    print('An exception occured')\n",
    "\n",
    "    \n",
    "data = model.topic_document.iloc[:, volume_indexes].iloc[35]\n",
    "\n",
    "ax = data.plot(title=\"Les Misérables, Topic #35 (barricade enjolras ...)\")\n",
    "ax.set_xlabel(\"Novel segment\")\n",
    "ax.set_ylabel(\"Topic share\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig(\"plot_topics_over_time_series_les_misérables.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are of many other topics that appear in our fit of the corpus. Looping\n",
    "over the topics and saving an image for each topic is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "for i in range(model.num_topics):\n",
    "    plt.clf()  # clears the current plot\n",
    "    plt.figure(figsize=(20,20))\n",
    "    series = model.topic_document.iloc[i].values\n",
    "    xs = np.arange(len(series))\n",
    "    series_smooth = rolling_mean(series, 15)  #mean window = 15\n",
    "    plt.plot(series, '.')\n",
    "    plt.plot(series_smooth, '-', linewidth=2)\n",
    "    plt.title(\"Topic {}: {}\".format(i, ','.join(model.topics.iloc[i, :10])))\n",
    "    savefig_fn = \"/tmp/hugo-topic{}.pdf\".format(i)\n",
    "    plt.savefig(savefig_fn, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fn-les-mis'></a>\n",
    "**[1]** The text of Les Misérables has been used in a variety of\n",
    "(interactive) visualization projects, including [Les Misérables\n",
    "Co-occurrence](http://bost.ocks.org/mike/miserables/) and [Novel Views:\n",
    "Les Miserables](http://neoformix.com/2013/NovelViews.html).\n",
    "\n",
    "<a id='fn-lowess'></a>\n",
    "**[2]** For generic smoothing those accustomed to using R will be\n",
    "familiar with the function `loess()` which implements the most common form\n",
    "of scatterplot smoothing. In Python a similar function\n",
    "(`statsmodels.nonparametric.lowess()`) is available in the `statsmodels`\n",
    "package. While we might be tempted to use such a function to communicate\n",
    "visually the basic trend, we will be better served if we think of the\n",
    "sequence of topic shares as a proper time series rather than (merely)\n",
    "a sequence of dependant and independent variables suitable for visualization\n",
    "in a scatter plot."
   ]
  }
 ],
 "metadata": {
  "date": 1.5771899409895773E9,
  "filename": "visualizing_trends.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "title": "Visualizing trends"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}