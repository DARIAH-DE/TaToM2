{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='index-0'></a>\n",
    "\n",
    "<a id='topic-model-mallet'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling with MALLET\n",
    "\n",
    "This section illustrates how to use [MALLET](http://mallet.cs.umass.edu/) to\n",
    "model a corpus of texts using a topic model and how to analyze the results using\n",
    "Python.\n",
    "\n",
    "A topic model is a probabilistic model of the words appearing in a corpus of\n",
    "documents.  (There are a number of general introductions to topic models\n",
    "available, such as [[Ble12]](references.ipynb#blei-introduction-2012).) The particular topic model\n",
    "used in this section is Latent Dirichlet Allocation (LDA), a model introduced in\n",
    "the context of text analysis in 2003 [[BNJ03]](references.ipynb#blei-latent-2003). LDA is an\n",
    "instance of a more general class of models called mixed-membership models. While\n",
    "LDA involves a greater number of distributions and parameters than the Bayesian\n",
    "model introduced in the section on [group comparison](feature_selection.ipynb#bayesian-group-comparison), both are instances of a Bayesian probabilistic\n",
    "model. In fact, posterior inference for both models is typically performed in\n",
    "precisely the same manner, using Gibbs sampling with conjugate priors.\n",
    "\n",
    "This section assumes prior exposure to topic modeling and proceeds as follows:\n",
    "\n",
    "1. MALLET is downloaded and used to fit a topic model of six novels, three by\n",
    "  Brontë and three by Austen. Because these are lengthy texts, the novels are split\n",
    "  up into smaller sections—a preprocessing step which improves results considerably.  \n",
    "1. The output of MALLET is loaded into Python as a document-topic matrix (a\n",
    "  2-dimensional array) of topic shares.  \n",
    "1. Topics, discrete distributions over the vocabulary, are analyzed.  \n",
    "\n",
    "\n",
    "Note that [an entire section](topic_model_visualization.ipynb#topic-model-visualization) is devoted to\n",
    "visualizing topic models. This section focuses on using MALLET and processing\n",
    "the results.\n",
    "\n",
    "This section uses six novels by Brontë and Austen. These novels are divided into\n",
    "parts as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überlegen ob der text unterhalb dazu passt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two columns of `doc-topics.txt` record the document number\n",
    "(0-based indexing) and the full path to the filename. The rest of the columns are best\n",
    "considered as (topic-number, topic-share) pairs. There are as many of these\n",
    "pairs as there are topics. All columns are separated by tabs (there’s even\n",
    "a trailing tab at the end of the line). With the exception of the header (the\n",
    "first line), this file records data using [tab-separated values](https://en.wikipedia.org/wiki/Tab-separated_values). There are two challenges\n",
    "in parsing this file into a document-topic matrix. The first is sorting.\n",
    "The texts do not appear in a consistent order in `doc-topics.txt` and the\n",
    "topic number and share pairs appear in different columns depending on the\n",
    "document. We will need to reorder these pairs before assembling them into\n",
    "a matrix.[#fnmapreduce]_ The second challenge is that the number of columns will\n",
    "vary with the number of topics specified (`--num-topics`). Fortunately, the\n",
    "documentation in the Python library [itertools](http://docs.python.org/dev/library/itertools.html) describes a function\n",
    "called `grouper` using `itertools.izip_longest` that solves our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text zur aktuellen mallet lage verfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import dariah\n",
    "import cophi\n",
    "\n",
    "jupyter_path = Path.cwd()\n",
    "directory= Path.joinpath(jupyter_path.resolve().parent.parent, 'data', 'austen-brontë-split')\n",
    "\n",
    "corpus = cophi.corpus(directory,\n",
    "                      lowercase=True,\n",
    "                      token_pattern=r\"\\p{Letter}+\\p{Connector_Punctuation}?\\p{Letter}+\",\n",
    "                      metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfw = corpus.mfw(50)\n",
    "features = mfw + corpus.hapax\n",
    "dtm = corpus.drop(corpus.dtm, features).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mallet becomes here a global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "mallet_path = os.environ.get(\"MALLET_HOME\")\n",
    "mallet_path == mallet_path + '\\bin\\mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'C:\\mallet' is not a file. Point to the 'mallet/bin/mallet' file.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-17-d17b18b84f15>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m model = dariah.core.LDA(num_topics=20,\n\u001B[0m\u001B[0;32m      2\u001B[0m                         \u001B[0mnum_iterations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                         mallet=mallet_path)\n\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\sib27sm\\venv\\lib\\site-packages\\dariah\\core\\modeling.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, num_topics, num_iterations, alpha, eta, random_state, mallet)\u001B[0m\n\u001B[0;32m     63\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mPath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m                 raise OSError(\n\u001B[0m\u001B[0;32m     66\u001B[0m                     \u001B[1;34m\"'{}' is not a file. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m                     \u001B[1;34m\"Point to the 'mallet/bin/mallet' file.\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmallet\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: 'C:\\mallet' is not a file. Point to the 'mallet/bin/mallet' file."
     ]
    }
   ],
   "source": [
    "model = dariah.core.LDA(num_topics=20,\n",
    "                        num_iterations=1000,\n",
    "                        mallet=mallet_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the topic model\n",
    "\n",
    "The first thing we should appreciate about our topic model is that the twenty\n",
    "shares do a remarkably good job of summarizing our corpus. For example, they\n",
    "preserve the distances between novels (see figures below). By this measure, LDA\n",
    "is good at dimensionality reduction: we have taken a matrix of dimensions 813 by\n",
    "14862 (occupying almost three megabytes of memory if stored in a spare matrix)\n",
    "and fashioned a representation that preserves important features in a matrix\n",
    "that is 813 by 20 (5% the size of the original).\n",
    "\n",
    "Even though a topic model “discards” the “fine-grained” information recorded in\n",
    "the matrix of word frequencies, it preserves salient details of the underlying\n",
    "matrix. That is, the topic shares associated with a document have an\n",
    "interpretation in terms of word frequencies. This is best illustrated by\n",
    "examining the present topic model.\n",
    "\n",
    "First let us identify the most significant topics for each text in the corpus.\n",
    "This procedure does not differ in essence from the procedure for identifying the\n",
    "most frequent words in each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.topic_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/dariah-topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.topic_document.to_csv('doc_topics_austen_brontë_20.csv', index=True)\n",
    "model.topics.to_csv('topics_austen_brontë_20.csv', index=True)\n",
    "model.topic_word.to_csv('word_austen_brontë_20.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ab hier zu Ende = alter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the average of the topic shares associated with each\n",
    "novel. Recall that we have been working with small sections of novels. The\n",
    "following step combines the topic shares for sections associated with the same\n",
    "novel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit into the space available, the table above displays the first 15\n",
    "of 20 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to parse this file into something we can work with. Fortunately this\n",
    "task is not difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to list the words associated with each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to inspect and to visualize topic models. Some of the more\n",
    "common methods are covered in [next section](topic_model_visualization.ipynb#topic-model-visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ab hier wieder wichtig = neuer Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinctive topics\n",
    "\n",
    "Finding distinctive topics is analogous to the task of [finding distinctive\n",
    "words](feature_selection.ipynb#feature-selection). The topic model does an excellent job of focusing\n",
    "attention on recurrent patterns (of co-occurrence) in the word frequencies\n",
    "appearing in a corpus. To the extent that we are interested in these kinds of\n",
    "patterns (rather than the rare or isolated feature of texts), working with\n",
    "topics tends to be easier than working with word frequencies.\n",
    "\n",
    "Consider the task of finding the distinctive topics in Austen’s novels. Here the\n",
    "simple difference-in-averages provides an easy way of finding topics that tend\n",
    "to be associated more strongly with Austen’s novels than with Brontë’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronte_cols = [\"Bronte\" in col for col in model.topic_document.columns]\n",
    "austen_cols = [\"Austen\" in col for col in model.topic_document.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronte_avg = model.topic_document.iloc[:, bronte_cols].mean(axis=1)\n",
    "austen_avg = model.topic_document.iloc[:, austen_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keyness = np.abs(austen_avg - bronte_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = np.argsort(keyness)[::-1]  # from highest to lowest; [::-1] reverses order in Python sequences\n",
    "ranking = np.argsort(keyness)[::-1]  # from highest to lowest; [::-1] reverses order in Python sequences\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fnmapreduce'></a>\n",
    "**[1]** Those familiar with [MapReduce](https://en.wikipedia.org/wiki/MapReduce) may recognize the pattern of splitting a dataset into smaller pieces and then (re)ordering them."
   ]
  }
 ],
 "metadata": {
  "date": 1.5771899409104617E9,
  "filename": "topic_model_mallet.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "title": "Topic modeling with MALLET"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}